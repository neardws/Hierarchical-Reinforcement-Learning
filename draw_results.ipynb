{"cells":[{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using matplotlib backend: agg\n"]}],"source":["%matplotlib\n","import matplotlib.pyplot as plt\n","from File_Name import project_dir, data\n","from Utilities.FileOperator import load_obj, load_name\n","import pandas as pd\n","import json\n","\n","pd.set_option('display.max_rows', None)\n","\n","# bandwidth = 3 and datasize = 1024  350\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1213_Agents/bandwidth_3_datasize_1024_01/2021-12-13-15-45-10-list_file_name.pkl\"\n","\n","# bandwidth = 1 and datasize = 1024 260\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_1_datasize_1024_01/2021-12-16-19-35-03-list_file_name.pkl\"\n","# bandwidth = 2 and datasize = 1024 340\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_2_datasize_1024_01/2021-12-16-19-35-30-list_file_name.pkl\"\n","# bandwidth = 4 and datasize = 1024 360\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_4_datasize_1024_01/2021-12-16-19-35-58-list_file_name.pkl\"\n","# bandwidth = 5 and datasize = 1024 380\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_5_datasize_1024_01/2021-12-16-19-36-41-list_file_name.pkl\"\n","\n","# bandwidth = 3 and datasize = 256  390\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_3_datasize_256_01/2021-12-16-19-34-19-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 512  390\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_3_datasize_512_01/2021-12-16-19-33-44-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 2048 300\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_3_datasize_2048_01/2021-12-16-19-31-15-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 4096 275\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1216_Agents/bandwidth_3_datasize_4096_01/2021-12-16-19-32-59-list_file_name.pkl\"\n","\n","\n","# IAC_GA\n","# bandwidth = 1 and datasize = 1024 \n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1231_IAC_GA/bandwidth_1_datasize_1024_01/2021-12-31-14-59-30-list_file_name.pkl\"\n","# bandwisth = 2 and datasize = 1024\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data1231_IAC_GA/bandwidth_2_datasize_1024_01/2021-12-31-15-00-06-list_file_name.pkl\"\n","\n","# C-DDPG\n","# bandwidth = 1 and datasize = 1024\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_1_datasize_1024/2022-01-09-18-51-08-list_file_name.pkl\"\n","# bandwidth = 2 and datasize = 1024\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_2_datasize_1024/2022-01-09-18-52-50-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 1024\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_1024/2022-01-09-18-53-21-list_file_name.pkl\"\n","# bandwidth = 4 and datasize = 1024\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_4_datasize_1024/2022-01-09-18-54-03-list_file_name.pkl\"\n","# bandwidth = 5 and datasize = 1024\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_5_datasize_1024/2022-01-09-18-55-31-list_file_name.pkl\"\n","\n","# bandwidth = 3 and datasize = 256\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_256/2022-01-09-18-57-06-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 512\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_512/2022-01-09-18-57-44-list_file_name.pkl\" \n","# bandwidth = 3 and datasize = 2048\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_2048/2022-01-09-18-58-30-list_file_name.pkl\"\n","# bandwidth = 3 and datasize = 4096\n","# correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_4096/2022-01-09-18-59-01-list_file_name.pkl\"\n","\n","# test\n","correct_list_file_name = \"/home/neardws/Hierarchical-Reinforcement-Learning/Data/Data0109_DDPG/bandwidth_3_datasize_4096/2022-01-10-15-12-31-list_file_name.pkl\"\n","\n","list_file = load_obj(name=correct_list_file_name)\n","init_agent_config = load_obj(load_name(list_file, \"init_agent_config_name\"))\n","# print(json.dumps(init_agent_config.__dict__, indent=4, separators=(',', ':')))\n","csv_file_name = load_name(list_file, 'temple_result_name')\n","df = pd.read_csv(csv_file_name, names=[\"Epoch index\", \"age_of_view\", \"new_age_of_view\", \"timeliness\", \"consistence\", \"completeness\", \"intel_arrival_time\", \"queuing_time\", \"transmitting_time\", \"service_time\", \"service_rate\", \"received_data\", \"required_data\"], header=0)\n","epoch_index = df[\"Epoch index\"].values.tolist()\n","rewards = df[\"age_of_view\"].values.tolist()\n","new_rewards = df[\"new_age_of_view\"].values.tolist()\n","# plt.plot(epoch_index, rewards, '-', color='b', label=\"R\")  # s-:方形\n","plt.plot(epoch_index, new_rewards, '--', color='g', label=\"NR\")  # o-:圆形\n","plt.show()\n","\n","csv_file_name = load_name(list_file, 'temple_loss_name')\n","df = pd.read_csv(csv_file_name, names=[\"Epoch index\",\n","                                    \"Actor of V1\", \"Actor of V2\", \"Actor of V3\",\n","                                    \"Actor of V4\", \"Actor of V5\", \"Actor of V6\",\n","                                    \"Actor of V7\", \"Actor of V8\", \"Actor of V9\",\n","                                    \"Actor of V10\",\n","                                    \"Critic of V1\", \"Critic of V2\", \"Critic of V3\",\n","                                    \"Critic of V4\", \"Critic of V5\", \"Critic of V6\",\n","                                    \"Critic of V7\", \"Critic of V8\", \"Critic of V9\",\n","                                    \"Critic of V10\",\n","                                    \"Actor of Edge\", \"Critic of Edge\",\n","                                    \"Actor of Reward\", \"Critic of Reward\"], header=0)\n","df = df[df[\"Epoch index\"] >= 0]\n","\n","\n","actor_loss_of_v1 = df[\"Actor of V1\"].values.tolist()\n","actor_loss_of_v2 = df[\"Actor of V2\"].values.tolist()\n","actor_loss_of_v3 = df[\"Actor of V3\"].values.tolist()\n","actor_loss_of_v4 = df[\"Actor of V4\"].values.tolist()\n","actor_loss_of_v5 = df[\"Actor of V5\"].values.tolist()\n","actor_loss_of_v6 = df[\"Actor of V6\"].values.tolist()\n","actor_loss_of_v7 = df[\"Actor of V7\"].values.tolist()\n","actor_loss_of_v8 = df[\"Actor of V8\"].values.tolist()\n","actor_loss_of_v9 = df[\"Actor of V9\"].values.tolist()\n","actor_loss_of_v10 = df[\"Actor of V10\"].values.tolist()\n","plt.plot(epoch_index, actor_loss_of_v1, '-', color='lightgreen', label='v1')\n","plt.plot(epoch_index, actor_loss_of_v2, '-', color='deepskyblue', label='v2')\n","plt.plot(epoch_index, actor_loss_of_v3, '-', color='midnightblue', label='v3')\n","plt.plot(epoch_index, actor_loss_of_v4, '-', color='pink', label='v4')\n","plt.plot(epoch_index, actor_loss_of_v5, '-', color='coral', label='v5')\n","plt.plot(epoch_index, actor_loss_of_v6, '-', color='gray', label='v6')\n","plt.plot(epoch_index, actor_loss_of_v7, '-', color='darkred', label='v7')\n","plt.plot(epoch_index, actor_loss_of_v8, '-', color='orange', label='v8')\n","plt.plot(epoch_index, actor_loss_of_v9, '-', color='blueviolet', label='v9')\n","plt.plot(epoch_index, actor_loss_of_v10, '-', color='black', label='v10')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n","\n","\n","critic_loss_of_v1 = df[\"Critic of V1\"].values.tolist()\n","critic_loss_of_v2 = df[\"Critic of V2\"].values.tolist()\n","critic_loss_of_v3 = df[\"Critic of V3\"].values.tolist()\n","critic_loss_of_v4 = df[\"Critic of V4\"].values.tolist()\n","critic_loss_of_v5 = df[\"Critic of V5\"].values.tolist()\n","critic_loss_of_v6 = df[\"Critic of V6\"].values.tolist()\n","critic_loss_of_v7 = df[\"Critic of V7\"].values.tolist()\n","critic_loss_of_v8 = df[\"Critic of V8\"].values.tolist()\n","critic_loss_of_v9 = df[\"Critic of V9\"].values.tolist()\n","critic_loss_of_v10 = df[\"Critic of V10\"].values.tolist()\n","plt.plot(epoch_index, critic_loss_of_v1, '-', color='lightgreen', label='v1')\n","plt.plot(epoch_index, critic_loss_of_v2, '-', color='deepskyblue', label='v2')\n","plt.plot(epoch_index, critic_loss_of_v3, '-', color='midnightblue', label='v3')\n","plt.plot(epoch_index, critic_loss_of_v4, '-', color='pink', label='v4')\n","plt.plot(epoch_index, critic_loss_of_v5, '-', color='coral', label='v5')\n","plt.plot(epoch_index, critic_loss_of_v6, '-', color='gray', label='v6')\n","plt.plot(epoch_index, critic_loss_of_v7, '-', color='darkred', label='v7')\n","plt.plot(epoch_index, critic_loss_of_v8, '-', color='orange', label='v8')\n","plt.plot(epoch_index, critic_loss_of_v9, '-', color='blueviolet', label='v9')\n","plt.plot(epoch_index, critic_loss_of_v10, '-', color='black', label='v10')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n","\n","actor_loss_of_edge = df[\"Actor of Edge\"].values.tolist()\n","plt.plot(epoch_index, actor_loss_of_edge, '-', color='lightgreen', label='actor')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n","\n","critic_loss_of_edge = df[\"Critic of Edge\"].values.tolist()\n","plt.plot(epoch_index, critic_loss_of_edge, '-', color='blueviolet', label='critic')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n","\n","actor_loss_of_reward = df[\"Actor of Reward\"].values.tolist()\n","plt.plot(epoch_index, actor_loss_of_reward, '-', color='lightgreen', label='actor')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n","\n","critic_loss_of_reward = df[\"Critic of Reward\"].values.tolist()\n","plt.plot(epoch_index, critic_loss_of_reward, '-', color='blueviolet', label='critic')\n","plt.legend(loc=\"best\")  # 图例\n","plt.show()\n"]}],"metadata":{"interpreter":{"hash":"7d147c52a3250c153b41f6801ca69df4aa9f1e4d9afa0ead463bb6a3a43b8876"},"kernelspec":{"display_name":"Python 3.8.8 64-bit ('base': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
